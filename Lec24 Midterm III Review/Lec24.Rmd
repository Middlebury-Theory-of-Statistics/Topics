---
title: "Midterm III Review"
author: "Albert Y. Kim"
date: "April 25th, 2016"
output: ioslides_presentation
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Install these packages first
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(readr)

# Set seed for random number generator
set.seed(76)
```

## Midterm Details

* Wednesday April 27th 7:30-10pm in Warner 506.
* Please bring a calculator; no smart phones.
* Everything up to and including Lec22 (Chapter 8.3).
* Need to understand everything from previous midterms to answer Midterm III questions.
* Allowed one double-sided 8.5 x 11 page which you'll be handing in.




## Studying Tips

* Exam is not timed to take entire time period.
* You don't need to memorize
    + R code, but write pseudocode.
    + Any statistical distributions.
* Some questions are
    + More straightforward: Can you regurgitate?
    + More conceptual: Did you get the bigger picture?
* Don't just focus on the **what/how** of the material and HW questions, but the **why**?





## Chapter 6: Properties of Estimators

* Only got to certain HW questions in this chapter after Midterm II.
* HW07 R Component Q2. We have two estimators of $\mathbb{P}(X \leq 1)$ for
$X_i$ Gamma distributed:
    + a **parametric** one $1-\exp\left(-\frac{1}{\overline{X}}\right)$ that 
    assumes the data is Gamma.
    + a **non-parametric** one $\frac{1}{n}\mathbb{1}(X_i \leq 1)$ that
    does not.




## Chapter 7: Confidence Intervals

Recall the 3 scenarios of CI's for the mean:

1. CI for Normal $\mu$, $\sigma$ known
1. CI for Normal $\mu$, $\sigma$ unknown
1. CI for for any $\mu$, $\sigma$ known

When do use one or another?






## Chapter 7: Confidence Intervals

* In general: How do you create a confidence interval for any parameter
$\theta$? What is the generalized method?
* What quantile value $q$ to use for
    + A two-sided CI
    + Upper CI
    + Lower CI
* Is $q$
    + Normally distributed?
    + $t$ distributed?
    




## Chapter 7: Confidence Intervals

A $(1-\alpha)\times 100\%$ two-sided confidence interval for difference in means $\mu_x - \mu_y$:

$$
\begin{align}
\left(\overline{X} - \overline{Y} \right) \pm q \sqrt{\frac{s_x^2}{n_x} + \frac{s_y^2}{n_y}}
\end{align}
$$

What are

* $q$? What distribution?
* Margin of Error?
* $\text{PE}$ and $\text{SE}$?





## Chapter 7: Pivot Method

* How does it work?
* Why do we need to use it?
* Go over examples in class.
    




## Chapter 7: CI for Proportions

* Obama support example: How do all the elements of a CI tie into poll reporting?
* In class we covered using a Normal quantile $q$ in our CI for proportions.
Under what conditions and why?

    



## Chapter 7: Types of CI's

What are the chief differences between the following:

* Classical CI's where math is the computational engine
* CI's where a computer is the computational engine
    + Bootstrap percentile interval
    + Bootstrap $t$ CI

When would you use one vs the other?
    



## Chapter 8: Hypothesis Testing

* Recall Midterm I question: a null distribution is an example of a sampling
distribution when $H_0$ is true.
* What is a null value?
* What is the general and common approach to almost all hypothesis tests?
* Recall $z$-score, but think of it in a HT context:

    



## Chapter 8: Types of Errors

* Understand the $2 \times 2$ contigency table of
    + Truth: $H_0$ and $H_A$
    + Decision: Fail to reject $H_0$ and Reject $H_0$
* Both types of errors/power and the tradeoff. Understand both statistically and
what they mean intuitively. Ex:
    + Criminal justice system
    + Airport security
    + Predicting gender
* What determines and how do we control the above? 





## Overall

We covered sampling distributions, standard errors, estimators, and other 
sampling theory in Chapters 1-6 (using both mathematical and computational
tools) **BEFORE** covering

* Chapter 7: Confidence interavls
* Chapter 8:  Hypothesis testing

Be able to articulate how the former ties into/dictates the latter.

    



## HW 6

* Properties of estimators. Tie them into **general sampling theory**.
* In HW6 and Questions 1-3 in HW 7
    + I give you summary statistics (Ex: $n$, $\overline{x}$, $s^2$), you give me a CI.
    + They both involve a lot of nitty gritty calculations. Understand CI's **in
genera.** in terms of $\text{PE}$, $q$, and $\text{SE}$?




## HW 7

* Creating CI's for less common parameters like $\sigma^2$. What is the general 
method for doing this?
* R Homework: For both questions, we compared two estimators of the same 
quantity. Why would we prefer one over the other **in practice**?





## HW 8

* Explicit Type I error, Type II error, and power questions. Don't just be able 
to do math, but think in terms of
    + **tradeoff** of errors 
    + original goal of hypothesis testing: we want to make a statement about a
    parameter $\theta$
* When do you think a particular kind of CI will outperform others?





