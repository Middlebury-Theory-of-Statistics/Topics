---
title: "Lecture 28"
author: "Albert Y. Kim"
date: "May 4th, 2016"
output: ioslides_presentation
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Install these packages first
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(readr)

# Set seed for random number generator
set.seed(76)
```

```{r, echo=FALSE, message=FALSE}
# Load data and run regression
library(resampledata)
# Set base plot
data(Skating2010)
Skating2010 <- Skating2010 %>% 
  tbl_df()
n <- nrow(Skating2010)
model <- lm(Free~Short, data=Skating2010)
Skating2010$residual <- resid(model)
```





## Recall: Figure Skating Scores

In Lec27 we studied the relationship between Short and Free program figure 
skating scores:

```{r, echo=FALSE}
p <- ggplot(data=Skating2010, aes(x=Short, y=Free)) +
  xlab("Short Program Score") + 
  ylab("Free Program Score")

# Base regression
p + 
  stat_smooth(method="lm", se=FALSE, col="black", size=0.5) + 
  geom_point(col="red")
```





## Regression Table for Skating

Regression output for all software looks something like this:

```{r, echo=FALSE, message=FALSE}
library(mosaic)
msummary(model)
```





## Bootstrap Regression

Now let's say the population isn't these `r n` skaters, but that these `r n` 
skaters are a sample from a hypothetical population of **potential olympic men's
figure skaters**.

We

1. Bootstrap resample `r n` skaters with replacement
1. Compute the least-squares line 
1. Repeat 1. and 2. 30 times





## Bootstrap Regression

We now have 30 bootstrapped regression lines:

```{r, echo=FALSE}
# Bootstrap regression
coeff <- data_frame(intercept=rep(0, 30), slope=rep(0, 30))
for(i in 1:30){
  bootstrap <- Skating2010[sample(1:n, n, replace=TRUE), ]
  coeff[i, ] <- coefficients(lm(Free~Short, data=bootstrap))
  p <- p + 
    geom_abline(intercept = coeff[i, 1], slope = coeff[i, 2], size=0.5)
}
p + 
  geom_point(col="red")
```





## Bootstrap Intercepts & Slopes

Let's get a better look at the intercepts and slopes by extending the ranges on
both axes.

```{r, echo=FALSE}
p + 
  geom_point(col="red") + 
  xlim(c(0, NA)) +
  ylim(c(min(coeff$intercept), NA))
```





## Example: Bootstrap Intercepts

Histogram of intercepts: the standard deviation i.e the SE is
`r round(sd(coeff$intercept), 3)`.

```{r, echo=FALSE}
ggplot(data=NULL, aes(x=coeff$intercept)) + 
  geom_histogram(bins=8) +
  geom_vline(xintercept = coef(model)[1], col="red") + 
  xlab("Bootstrap Intercept")
```





## Example: Bootstrap Slopes

Histogram of slopes: the standard deviation i.e the SE is
`r round(sd(coeff$slope), 3)`.

```{r, echo=FALSE}
ggplot(data=NULL, aes(x=coeff$slope)) + 
  geom_histogram(bins=12) +
  geom_vline(xintercept = coef(model)[2], col="red") + 
  xlab("Bootstrap Slopes") + 
  xlim(c(0, NA))
```





## Permutation Test

We can test if there is a relationship between Short and Free program scores.

i.e.

$$
\begin{align}
&H_0: \text{Short and Free are unrelated}\\
\text{vs.} &H_A: \text{Short and Free are related}
\end{align}
$$





## Permutation Test

Under $H_0$ Short and Free are unrelated, so we can take the original data:

```{r, echo=FALSE}
subset <- Skating2010 %>% 
  select(Short, Free) %>% 
  slice(1:3) 
subset %>% 
  kable()
```





## Permutation Test

and permute the rows to no effect.

```{r, echo=FALSE}
subset <- subset[sample(1:3),]
subset %>%   
  kable()
```





## Permutation Test

Just like the permutation test before:

```{r}
# Data
Short <- Skating2010$Short
Free <- Skating2010$Free
n <- nrow(Skating2010)

# Compute observed correlation coefficient and slope
r <- cor(Free, Short)
model <- lm(Free~Short)
b <- coef(model)[2]
```





## Permutation Test

We **resample without replacement** to permute/reshuffle the pairs of observations:

```{r, cache=TRUE}
N <- 10^4
perm_r <- rep(0, N)
perm_b <- rep(0, N)

for(i in 1:N){
  index <- sample(1:n, n, replace = FALSE)
  perm_r[i] <- cor(Free, Short[index])
  
  perm_model <- lm(Free~Short[index])
  perm_b[i] <- coef(perm_model)[2]
}
```





## Permutation Test

The observed correlation coefficient and slope are in red. The (two-sided) p-values, are both very small.

```{r, echo=FALSE}
par(mfrow=c(1,2))
hist(perm_r, xlab = "cor coeff", main="Permuted Correlation Coeff", xlim = range(c(-r, r)))
abline(v=r, col="red", lwd=1.5)
abline(h=0)
hist(perm_b, xlab = "slope", main="Permuted Slope", xlim = range(c(-b, b)))
abline(v=b, col="red", lwd=1.5)
abline(h=0)
```

